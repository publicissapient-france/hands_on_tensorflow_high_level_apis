{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10 with tf.keras, tf.data and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:00:26.298135Z",
     "start_time": "2019-04-19T08:00:22.479229Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:00:27.560189Z",
     "start_time": "2019-04-19T08:00:27.556209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python version 3.5 or 3.6\n",
    "assert sys.version_info >= (3, 5)\n",
    "assert sys.version_info < (3, 7)\n",
    "# Tensorflow 2.0\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we are trying to solve here is to perform a sentiment analysis task on a movie reviews dataset, IMDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the new API called [TensorFlow Datasets](https://www.tensorflow.org/datasets), which gives access to a large collection of ready to use datasets, which are exposed as `tf.data.Datasets` for performant input pipelines.\n",
    "\n",
    "We will load the `imdb_reviews` dataset.\n",
    "\n",
    "Documentation : https://www.tensorflow.org/datasets/datasets#imdb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:04:19.410310Z",
     "start_time": "2019-04-19T08:00:31.724759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
    "                                  batch_size=-1, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy arrays for further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:04:25.014949Z",
     "start_time": "2019-04-19T08:04:24.926986Z"
    }
   },
   "outputs": [],
   "source": [
    "train_examples, train_labels = tfds.as_numpy(train_data)\n",
    "x_test, y_test = tfds.as_numpy(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:04:26.738116Z",
     "start_time": "2019-04-19T08:04:26.733858Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_examples[10000:]\n",
    "x_val = train_examples[:10000]\n",
    "\n",
    "y_train = train_labels[10000:]\n",
    "y_val = train_labels[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:04:59.628041Z",
     "start_time": "2019-04-19T08:04:59.622886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training entries: {}, test entries: {}\".format(len(train_examples), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:02.130404Z",
     "start_time": "2019-04-19T08:05:02.124181Z"
    }
   },
   "outputs": [],
   "source": [
    "train_examples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:06.844917Z",
     "start_time": "2019-04-19T08:05:06.838084Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf.data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:08.815417Z",
     "start_time": "2019-04-19T08:05:08.812633Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go back to a `tf.data.Dataset` format.\n",
    "\n",
    "For the train set, the following steps are performed :\n",
    "- Convert to dataset with the `from_tensor_slices` function\n",
    "- Shuffle with buffer size 10000\n",
    "- Batch\n",
    "- Repeat\n",
    "\n",
    "> <div class=\"mark\">Create the input pipeline for the train set</div><i class=\"fa fa-lightbulb-o \"></i>\n",
    "\n",
    "Documentation : \n",
    "- https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "ds_train = tf.data.Dataset. # TODO\n",
    "# Shuffle\n",
    "ds_train = # TODO\n",
    "# Batch\n",
    "ds_train = # TODO\n",
    "# Repeat\n",
    "ds_train = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go back to a `tf.data.Dataset` format.\n",
    "\n",
    "The test set is only composed of the following steps :\n",
    "- Convert to dataset with the `from_tensor_slices` function\n",
    "- Batch\n",
    "\n",
    "> <div class=\"mark\">Create the input pipeline for the test set</div><i class=\"fa fa-lightbulb-o \"></i>\n",
    "\n",
    "Documentation : \n",
    "- https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "ds_test = tf.data.Dataset. # TODO\n",
    "# Batch\n",
    "ds_test = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:23.927791Z",
     "start_time": "2019-04-19T08:05:23.924941Z"
    }
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Neural Network will now be composed of the following layer : \n",
    "- `KerasLayer` : add the `module_url`, the output_shape ([OUTPUT_SHAPE]), the input_shape ([]), dtype=tf.string and set `trainable` to False\n",
    "- `Dense` Layer : 16 neurons, relu activation\n",
    "- `Dense` Layer : 1 neuron, sigmoid activation\n",
    "\n",
    "> <div class=\"mark\">Create the model</div><i class=\"fa fa-lightbulb-o \"></i>\n",
    "\n",
    "Documentation : \n",
    "- https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer?hl=en\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:27:28.138274Z",
     "start_time": "2019-03-24T19:27:28.017642Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_SHAPE = 20\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly classified).\n",
    "\n",
    "You will implement the following compilation step for your Neural Network : \n",
    "- \"adam\" optimizer\n",
    "- \"binary_crossentropy\" loss\n",
    "- metric : \"accuracy\"\n",
    "\n",
    "Documentation : https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:32.189096Z",
     "start_time": "2019-04-19T08:05:32.036830Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:34.785632Z",
     "start_time": "2019-04-19T08:05:34.780040Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:14:34.658684Z",
     "start_time": "2019-03-19T10:14:34.653107Z"
    }
   },
   "source": [
    "We are now ready to train our network, which in Keras is done via a call to the `fit` method of the network: \n",
    "we \"fit\" the model to its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will fit the network with the following configurations :\n",
    "- `x`: ds_train\n",
    "- `epochs` : 15 (passes on the whole dataset)\n",
    "- `steps_per_epoch`: 150 steps\n",
    "- `validation_data`: ds_test\n",
    "- `validation_steps`: 10\n",
    "- `callbacks`: tensorboard\n",
    "\n",
    "You will also add a callback for launching TensorBoard to observe how the training is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:05:38.536293Z",
     "start_time": "2019-04-19T08:05:38.532609Z"
    }
   },
   "outputs": [],
   "source": [
    "LOG_DIR = './tensorboard/tf_keras_data_hub'\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1, update_freq=\"batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"mark\">Fit the model with the above information.</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
    "\n",
    "model. # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the accuracy of the network over the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance visualisation with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the following command, click on the suggested link (virtualenv users) or open a new tab and go to 127.0.0.1:6006 (Docker users) to open Tensorboard.\n",
    "\n",
    "Once finished, click on the STOP botton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T08:06:30.198505Z",
     "start_time": "2019-04-19T08:06:11.882858Z"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir \"tensorboard/\" --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check that our model performs well on the test set too.\n",
    "\n",
    "You can do this by calling the `evaluate` method of your network on the test set (use 300 for the `steps` argument).\n",
    "\n",
    "Documentation : https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate\n",
    "\n",
    "> <div class=\"mark\">Evaluate the model performance on test set</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model. # TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "256px",
    "width": "264px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
